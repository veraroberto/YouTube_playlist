{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80225057-1577-46f0-829f-f07a785eaa62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from API_KEY import *\n",
    "import pandas as pd\n",
    "from YouTube_fnc import *\n",
    "import isodate, pickle, math, pycountry, requests, string, time, os, itertools, pyperclip, re, unicodedata, time\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo \n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from pathlib import Path\n",
    "\n",
    "from app import *\n",
    "start_program = time.time()\n",
    "quota_filename = stats_folder / 'Quota.csv'\n",
    "quota = get_today_quota(quota_filename, True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b12d56-7580-4aff-9878-cc27ebe969cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Add Manually and ID**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b550c5b-1622-4113-a3ec-a6990753602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the video ID manually into the File\n",
    "video_id = get_video_id(input('Add a video ID manually: ').strip())\n",
    "print(yt_url + video_id)\n",
    "response = get_response_video_id(youtube, quota_filename, video_id)\n",
    "metadata_video = get_metadata_video(response)\n",
    "channelId = response['items'][0]['snippet']['channelId']\n",
    "response_channel = get_channel_response(youtube, quota_filename, channelId)\n",
    "handle = response_channel['items'][0]['snippet']['customUrl'].replace('@', '')\n",
    "print(f'The YouTube handle is: {handle}')\n",
    "print(f'https://www.youtube.com/channel/{channelId}')\n",
    "for info in metadata_video:\n",
    "    print(info)\n",
    "handle_file_path = Content_Creator_folder / f'{handle}.txt'\n",
    "\n",
    "if handle_file_path.exists():\n",
    "    print(handle_file_path)\n",
    "    add_element_to_file(handle_file_path, video_id, True, True)\n",
    "else:\n",
    "    clear_output(wait=False)\n",
    "    print('Not Added')\n",
    "#     handle = get_podcast_name_videoID(YT_content_creators, video_id, channelId, youtube, quota_filename)\n",
    "#     if handle:\n",
    "#         handle_file_path = Content_Creator_folder / f'{handle}.txt'\n",
    "#         print(handle_file_path)\n",
    "#         add_element_to_file(handle_file_path, video_id, True, True)\n",
    "#     else:\n",
    "#         print(f'The handle {handle} file does not exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c520d82-5f41-4520-b3ad-6e90bee9241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = 'PLpLSuxy9E5PzSGFREY8nXEsRGXNZ9xDYI'\n",
    "video_ids = get_all_ids_playlist(youtube, quota_filename, playlist_id,10)\n",
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fcb7a4-3f3a-46f9-b02b-54f48502d486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9ac86-8062-4f0c-bea7-07d5c29e027e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bae83-f1e0-4c2b-a57c-a5c301b6139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_restricted(response):\n",
    "    items = response['items']\n",
    "    if items:\n",
    "        details = items[0]['contentDetails']\n",
    "        regionRestriction = details.get('regionRestriction',{})\n",
    "        blocked = regionRestriction.get('blocked', [])\n",
    "        allowed = regionRestriction.get('allowed', [])\n",
    "        if current_country in blocked or (allowed and current_country not in allowed):\n",
    "            return True\n",
    "    else:\n",
    "#         print('There is no items response')\n",
    "        return \"There is no items response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5490a-fbea-42c4-887c-9458244a7866",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "restricted_ids= []\n",
    "for index, video_id in enumerate(video_ids[53:], 1):\n",
    "    response = get_response_video_id(youtube, quota_filename, video_id)\n",
    "    if is_restricted(response) == True or is_restricted(response) == \"There is no items response\":\n",
    "        restricted_ids.append(video_id)\n",
    "        print(f'{index:03d} {yt_url}{video_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856b7db-657f-4974-b54e-9f170b435023",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(restricted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55363a95-365a-43c9-8c94-97747d4ce836",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'WUYHC0czVTo'\n",
    "response = get_response_video_id(youtube, quota_filename, video_id)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198adc95-1f64-42d2-9637-bb0733dbd323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688df02-978e-4a86-ab61-7baedea436a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = get_video_id(input('Video ID: '))\n",
    "response = get_response_video_id(youtube, quota_filename, video_id)\n",
    "\n",
    "metadata_video = get_metadata_video(response)\n",
    "for metadata in metadata_video:\n",
    "    print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b7766-b1eb-4334-bf14-3b572ebced70",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007e81d-2971-4b2c-b96c-21c5e27373b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7521be97-4868-4158-9d4f-47b87dd39671",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Add video ids lists to files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17373dc-99f0-4e20-aeb7-579b4a791b3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "youtube_copy = pyperclip.paste()\n",
    "youtube_list = [yt_url + get_video_id(url) for url in sorted(youtube_copy.splitlines(), key=get_index)]\n",
    "youtube_list = list(dict.fromkeys(youtube_list))\n",
    "for index, yt in enumerate(youtube_list, 1):\n",
    "    print(f'{index:02d} {yt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a0a89-3631-4cc5-acd5-c830d32e3187",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "used_video_id = []\n",
    "for url in youtube_list:\n",
    "    video_id = get_video_id(url)\n",
    "    if video_id in used_video_id:\n",
    "        print(f'Video ID {video_id} already used in this loop')\n",
    "        print('-'*100)\n",
    "        continue\n",
    "    response = get_response_video_id(youtube, quota_filename, video_id)\n",
    "    metadata_video = get_metadata_video(response)\n",
    "    items = response['items']\n",
    "    if not items:\n",
    "        continue\n",
    "    channelId = items[0]['snippet']['channelId']\n",
    "    response_channel = get_channel_response(youtube, quota_filename, channelId)\n",
    "    handle = response_channel['items'][0]['snippet']['customUrl'].replace('@', '')\n",
    "\n",
    "    print(f'The YouTube handle is: {handle}')\n",
    "    print(f'https://www.youtube.com/channel/{channelId}')\n",
    "    for info in metadata_video:\n",
    "        print(info)\n",
    "\n",
    "    handle_file_path = Content_Creator_folder / f'{handle}.txt'\n",
    "\n",
    "    if handle_file_path.exists():\n",
    "        print(handle_file_path)\n",
    "        add_element_to_file(handle_file_path, video_id, True, True)\n",
    "    else:\n",
    "        print(f'{handle}')\n",
    "        print('The handle file does not exists')\n",
    "    print('-'*100)\n",
    "    used_video_id.append(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f774d1d-5579-4ed5-9446-b8661b815ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = input('Video ID').strip().replace(yt_url, '')\n",
    "response = get_response_video_id(video_id)\n",
    "if response['items']:\n",
    "    contentDetails = response['items'][0]['contentDetails']\n",
    "    publishedAt = response['items'][0]['snippet']['publishedAt']\n",
    "    title = response['items'][0]['snippet']['title']\n",
    "    channelTitle = response['items'][0]['snippet']['channelTitle'] \n",
    "    duration_iso = response['items'][0]['contentDetails'].get('duration', 'PT0S')\n",
    "    duration = isodate.parse_duration(duration_iso).total_seconds()\n",
    "    print(publishedAt)\n",
    "    print(title)\n",
    "    print(channelTitle)\n",
    "    print(f'Duration of the video -> {duration_string(duration)}')\n",
    "    if is_restricted(response):   \n",
    "        regionRestriction = contentDetails.get('regionRestriction',{})\n",
    "        print(regionRestriction)\n",
    "    print(yt_url + video_id)\n",
    "else:\n",
    "    print('No ITEMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a336f-49e3-4fa8-adf7-ec45f3e7558a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7af27-955e-49d4-9694-f04882b53dcb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "alignment = YT_content_creators['Channel Name'].map(len).max()\n",
    "for index, row in YT_content_creators.iterrows():\n",
    "    print(f'{index:03d}\\t{row[\"Channel Name\"]:<{alignment}} https://www.youtube.com/channel/{row[\"Channel ID\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fda931-04d3-4055-a151-a43751e47d2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Check if a Handle is in the DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1e2e3-7ef1-4156-bca4-aad2a8bfca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_to_check = remove_accents(input('Handle to Check ').lower())\n",
    "if handle_to_check not in handle in YT_content_creators['Handle'].values:\n",
    "    print(f'The Handle {handle_to_check} is not in the DataFrame ')\n",
    "\n",
    "YT_content_creators[YT_content_creators['Handle'] == handle_to_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb59e62-14e9-4ce4-a5bc-f92f0048050e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Skip Titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab45ea4-15b6-4a53-b923-4354ec9ebca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_title_path = Path('Exceptions') / 'skip_title.txt'\n",
    "skip_title = remove_accents(input('Skip the title in video: ').strip().lower())\n",
    "add_element_to_file(skip_title_path, skip_title, True, True)\n",
    "titles_list = skip_title_path.read_text().splitlines()\n",
    "titles_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f31469-9364-4281-b420-47cd589f3844",
   "metadata": {},
   "source": [
    "# **Only Add Long Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6796de-0bf3-4e11-a9cd-db5a51bed1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_add_long_videos_path = Path('Exceptions') / 'only_add_long_videos.txt'\n",
    "only_long_handle = remove_accents(input('Only add long videos from Handle: ').strip().lower())\n",
    "add_element_to_file(only_add_long_videos_path, only_long_handle, True, True)\n",
    "only_long_videos = only_add_long_videos_path.read_text().splitlines()\n",
    "only_long_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c900574-19de-46f4-bccc-14c1077d71a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Live Videos to ignore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231a20c-0f65-4df2-be08-8b987030cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_live_handle = Path('Exceptions') / 'skip_live_handle.txt'\n",
    "live_to_skip = remove_accents(input('Handle to skip in liveStreamingDetails: ').strip().lower())\n",
    "add_element_to_file(skip_live_handle, live_to_skip, True, True)\n",
    "skip_liveStreamingDetails_handle = skip_live_handle.read_text().splitlines()\n",
    "skip_liveStreamingDetails_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb51ba-f45e-46b7-bea5-008185b9f601",
   "metadata": {},
   "source": [
    "# **Handle to Skip in Shorts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848a031-e35b-4173-a74e-41a7a48ec017",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_handle_shorts_path = Path('Exceptions') / 'skip_shorts_handle.txt'\n",
    "handle_to_skip = remove_accents(input('Handle to skip in Shorts: ').strip().lower().replace('@',\"\"))\n",
    "add_element_to_file(skip_handle_shorts_path, handle_to_skip, True, True)\n",
    "skip_shorts_handle = skip_handle_shorts_path.read_text().splitlines()\n",
    "skip_shorts_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88862125-8046-4fae-92b0-96d969d2761f",
   "metadata": {},
   "source": [
    "# **Skip long Videos from Handle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b3891-1497-4413-b851-4efa572ae3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_long_videos_60m_path = Path('Exceptions') / 'skip_long_videos_60m.txt'\n",
    "skip_long_videos_60m_path.touch()\n",
    "handle_to_skik_long_vide = remove_accents(input('Handle to skip in Shorts: ').strip().lower().replace('@',\"\"))\n",
    "add_element_to_file(skip_long_videos_60m_path, handle_to_skik_long_vide, True, True)\n",
    "skip_long_videos = skip_long_videos_60m_path.read_text().splitlines()\n",
    "skip_long_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109699ec-3be1-424e-9819-713333bea17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_content_creators.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc39c7c-f13c-4d38-9ba8-78a38a103c77",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f6a6a-a04c-46fd-b63c-27c3d0fdd607",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESET = \"\\033[0m\"\n",
    "background = '\\033[48;2;211;211;211m'#   # white/gray background\n",
    "\n",
    "       \n",
    "alignment_channel = YT_content_creators['channelName'].map(len).max()\n",
    "alignment_handle = YT_content_creators['Handle'].map(len).max()\n",
    "\n",
    "for index, row in YT_content_creators.iterrows():\n",
    "    if row[\"uploadsID\"].startswith(\"PL\"):\n",
    "        row_info  = f'{index:03d} {row[\"Handle\"][0:alignment_channel]:<{alignment_channel}} https://www.youtube.com/playlist?list={row[\"uploadsID\"]}'\n",
    "\n",
    "    else:    \n",
    "\n",
    "        row_info  = f'{index:03d} {row[\"Handle\"]:<{alignment_channel}} https://www.youtube.com/channel/{row[\"channelID\"]}{\" \"*16}'\n",
    "    if index % 2 == 0:\n",
    "        print(f\"{background}{row_info} {RESET}\")\n",
    "    else:\n",
    "        print(row_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecb209-c99c-4080-879e-0286a82a428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3eacb1-675b-4c5b-a69d-bf3d567e3779",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESET = \"\\033[0m\"\n",
    "background = '\\033[48;2;211;211;211m'#   # white/gray background\n",
    "\n",
    "       \n",
    "alignment = YT_content_creators['Handle'].map(len).max()\n",
    "for row in YT_content_creators.itertuples():\n",
    "#     print(row.channelName)\n",
    "    row_info  = f'{row.Index:03d} {row.Handle:<{alignment}} https://www.youtube.com/channel/{row.channelID}'\n",
    "    if row.Index % 2 == 0:\n",
    "        print(f\"{background}{row_info} {RESET}\")\n",
    "    else:\n",
    "        print(row_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f8d77-7454-434e-afcc-7da1d94dbd57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in playlist_folder.iterdir():\n",
    "    if file.suffix == '.txt' and not file.stem.startswith('.'):\n",
    "        elements = get_elements_from_file(file)\n",
    "        print(f'{file.stem.replace(\"_\", \" \")}: {len(elements)}')\n",
    "        for index, e in enumerate( elements, 1):\n",
    "            print(f'\\t{index:02d} https://www.youtube.com/@' + e)\n",
    "\n",
    "        print('-'*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcffea-930f-422c-a44d-b6818c92a0ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YT_content_creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d4679-3653-4499-98b3-b88c7e62e58c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Handle to Remove from Files**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d75b6736-02eb-45ea-b0b5-aa40c957acb7",
   "metadata": {},
   "source": [
    "bote_pronto_con_carlos_puig\n",
    "codigo_negro_con_oscar_balderas\n",
    "esquina_balderas\n",
    "hablemos_con_denise_maerker\n",
    "la_entrevista_con_sarmiento\n",
    "la_silla_roja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f270b4-9a3c-40f7-a01a-cf6ca7add3fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RESET = \"\\033[0m\"\n",
    "background = '\\033[48;2;211;211;211m'#   # white/gray background\n",
    "\n",
    "       \n",
    "alignment = YT_content_creators['channelName'].map(len).max()\n",
    "for index, row in YT_content_creators.iterrows():\n",
    "    row_info  = f'{index:03d} {row[\"Handle\"]:<{alignment}} https://www.youtube.com/channel/{row[\"channelID\"]}'\n",
    "    if index % 2 == 0:\n",
    "        print(f\"{background}{row_info} {RESET}\")\n",
    "    else:\n",
    "        print(row_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ea581-7c60-4f27-9d8a-91af98e5972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_files = list(playlist_folder.glob('*.txt'))\n",
    "youtube_names = [playlist.stem.replace('_', ' ').strip() for playlist in playlist_files]\n",
    "youtube_names.sort()\n",
    "handle_to_remove = remove_accents(input('Remove handle: ').lower().strip())\n",
    "delete_from_df = choose_option([True, False], 'Delete Handle from Data Frame? ')\n",
    "if delete_from_df:\n",
    "    if handle_to_remove in YT_content_creators['Handle'].iloc(0):\n",
    "        print(f'{handle_to_remove} was removed from de DataFrame')\n",
    "    YT_content_creators = YT_content_creators[YT_content_creators['Handle'] != handle_to_remove]\n",
    "    YT_content_creators.to_csv(file_path_yt_creators,  index=False)\n",
    "    file_path_to_delete = Content_Creator_folder / f'{handle_to_remove}.txt'\n",
    "    if file_path_to_delete.exists():\n",
    "        file_path_to_delete.unlink()\n",
    "        print(f\"{file_path_to_delete.stem} was deleted.\")\n",
    "    else:\n",
    "        print(f'{file_path_to_delete.stem} was not found')\n",
    "\n",
    "\n",
    "handle_found = False\n",
    "for file in playlist_files:\n",
    "    handles_in_file = file.read_text().splitlines()\n",
    "    if handle_to_remove in handles_in_file:\n",
    "        handles_in_file.remove(handle_to_remove)\n",
    "        new_handles = '\\n'.join(handles_in_file)\n",
    "        file.write_text(new_handles)\n",
    "        file_to_print = file.stem.replace('_',' ').strip()\n",
    "        print(f'The handle {handle_to_remove} was removed from {file_to_print}')\n",
    "        handle_found = True\n",
    "if not handle_found:\n",
    "    print(f'The handle {handle_to_remove} was not found in any file ')\n",
    "\n",
    "exceptions_files = list(exceptions_folder.glob('*.txt'))\n",
    "handle_found = False\n",
    "for file in exceptions_files:\n",
    "    handles_in_file = file.read_text(encoding=\"utf-8\").splitlines()\n",
    "    if handle_to_remove in handles_in_file:\n",
    "        handles_in_file.remove(handle_to_remove)\n",
    "        new_handles = '\\n'.join(handles_in_file)\n",
    "        file.write_text(new_handles)\n",
    "        file_to_print = file.stem.replace('_',' ').strip()\n",
    "        print(f'The handle {handle_to_remove} was removed from {file_to_print}')\n",
    "        handle_found = True\n",
    "if not handle_found:\n",
    "    print(f'The handle {handle_to_remove} was not found in any Exception File')\n",
    "    \n",
    "if not delete_from_df:\n",
    "    only_delete_handle = 'Do not add the handle to any Playlist'\n",
    "    new_playlist = 'Create a new playlist: '\n",
    "    options = youtube_names + [only_delete_handle, new_playlist]\n",
    "    option_choosen = choose_option(options)\n",
    "\n",
    "    if option_choosen == only_delete_handle:\n",
    "        print(f'The Handle \"{handle_to_remove}\" was deleted and not added to any playlist')\n",
    "    elif option_choosen == new_playlist:\n",
    "        new_playlist = remove_accents(input('New Playlist name: ').strip().replace(' ', '_'))\n",
    "        file_path = playlist_folder / f'{new_playlist}_handles.txt'\n",
    "        add_element_to_file(file_path, handle_to_remove, True, True)\n",
    "    else:\n",
    "        playlist = option_choosen.replace(' ', '_')\n",
    "        file_path = playlist_folder / f'{playlist}_handles.txt'\n",
    "        add_element_to_file(file_path, handle_to_remove, True, True)\n",
    "\n",
    "playlist_files = list(playlist_folder.glob('*.txt'))\n",
    "youtube_names = [playlist.stem.replace('_', ' ').strip() for playlist in playlist_files]\n",
    "if delete_from_df:\n",
    "    YT_content_creators = pd.read_csv(file_path_yt_creators)\n",
    "    YT_content_creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2091b4-4060-4194-a7b3-37d17dc23aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions_folder = Path('Exceptions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd20bb9-d586-4095-8576-bc714a3debfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Add new Handle to Data Frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df7331-558a-426c-8606-48d2706ab272",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = remove_accents(input(\"New Handle: \").replace('@', \"\").lower().strip())\n",
    "playlist_files = list(playlist_folder.glob('*.txt'))\n",
    "youtube_names = [playlist.stem.replace('_', ' ').strip() for playlist in playlist_files]\n",
    "handle = handle.lower()\n",
    "if handle in YT_content_creators['Handle'].values:\n",
    "    print(f'Handle {handle} is already in the DataFrame')\n",
    "\n",
    "else:\n",
    "    print(f'Adding the Handle {handle}')\n",
    "    other_options = ['Other Videos', 'Create a new Playlist']\n",
    "    youtube_names.sort()\n",
    "    youtube_names.extend(other_options)\n",
    "    option_choosen = choose_option(youtube_names)\n",
    "    if option_choosen == other_options[0]:\n",
    "        print('Video not added in any particular Playlist')\n",
    "    elif option_choosen == other_options[-1]:\n",
    "        new_playlist = remove_accents(input('Name of the new Playlist: ').strip())\n",
    "        file = new_playlist.replace(' ', '_') + '.txt'\n",
    "        playlist_handle_filepath = playlist_folder / file\n",
    "        add_element_to_file(playlist_handle_filepath, handle, True, True)\n",
    "\n",
    "    else:\n",
    "        file = option_choosen.replace(' ','_') + '.txt'\n",
    "        playlist_handle_filepath = playlist_folder / file\n",
    "        add_element_to_file(playlist_handle_filepath, handle, True, True)\n",
    "\n",
    "    inicio = time.time()\n",
    "    channelId, channelTitle, uploads_playlist_id = get_response_channelby_handle(youtube, quota_filename, handle)\n",
    "    # youtube, quota_filename, playlist_id, max_iternations = 5\n",
    "    video_ids_yt = get_all_ids_playlist(youtube, quota_filename, uploads_playlist_id,900)\n",
    "    if video_ids_yt:    \n",
    "        print(f'Time getting the video ids: {duration_string(time.time() - inicio)}')\n",
    "        file_path = Content_Creator_folder / f'{handle}.txt'\n",
    "        print(f'{handle} has {len(video_ids_yt):,} videos')\n",
    "        new_row = handle, channelTitle, channelId, uploads_playlist_id\n",
    "        elements = video_ids_yt[1:]\n",
    "        add_list_to_file(file_path, elements, sort_list = False)\n",
    "        YT_content_creators.loc[len(YT_content_creators)] = new_row\n",
    "        YT_content_creators.sort_values(by='Handle', inplace = True,  key=lambda col: col.str.lower())\n",
    "        YT_content_creators.reset_index(drop=True, inplace=True)\n",
    "        YT_content_creators.to_csv(file_path_yt_creators, index=False)\n",
    "        print(f'The duration to write the file was: {duration_string(time.time() - inicio)}')\n",
    "    else:\n",
    "        print('Handle was not added to the CSV, check the quota usage')\n",
    "add_exception_to_file(handle)\n",
    "playlist_files = list(playlist_folder.glob('*.txt'))\n",
    "youtube_names = [playlist.stem.replace('_', ' ').strip() for playlist in playlist_files]\n",
    "YT_content_creators = pd.read_csv(file_path_yt_creators)\n",
    "get_today_quota(quota_filename, True)\n",
    "print('https://www.youtube.com/@' + handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80380a63-f943-4e6c-b909-48660128defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response_channelby_handle(youtube, quota_filename, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42aa0c2-0690-49ba-8bc1-afb8861b6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['items'][0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0743a3-280f-4103-b5f9-5dc622d03031",
   "metadata": {},
   "source": [
    "# **Add new Row to Data Frame by Video ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa479da-fa42-4630-bbbf-2fa12f734a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_files = list(playlist_folder.glob('*.txt'))\n",
    "youtube_names = [playlist.stem.replace('_', ' ').strip() for playlist in playlist_files]\n",
    "video_id = input('Video_id: ').replace(yt_url,'').strip()\n",
    "response = get_response_video_id(video_id)\n",
    "channelId = response['items'][0]['snippet']['channelId']\n",
    "\n",
    "if channelId in YT_content_creators['Channel ID'].values:\n",
    "    Handle = YT_content_creators[YT_content_creators['Channel ID'] ==  channelId]['Handle'].iloc[0]\n",
    "    print(f'{Handle} Already in Data Frame')\n",
    "\n",
    "else:\n",
    "    channel_response = get_channel_response(channelId)\n",
    "    handle = channel_response['items'][0]['snippet']['customUrl'].replace('@',\"\")\n",
    "    \n",
    "    other_options = ['Other Videos', 'Create a new Playlist']\n",
    "    youtube_names.extend(other_options)\n",
    "    option_choosen = choose_option(youtube_names)\n",
    "    if option_choosen == other_options[0]:\n",
    "        print('Video not added in any particular Playlist')\n",
    "    elif option_choosen == other_options[-1]:\n",
    "        new_playlist = remove_accents(input('Name of the new Playlist: ').strip())\n",
    "        file = new_playlist.replace(' ', '_') + '.txt'\n",
    "        playlist_handle_filepath = playlist_folder / file\n",
    "        add_element_to_file(playlist_handle_filepath, handle, True, True)\n",
    "\n",
    "    else:\n",
    "        file = option_choosen.replace(' ','_') + '.txt'\n",
    "        playlist_handle_filepath = playlist_folder / file\n",
    "        add_element_to_file(playlist_handle_filepath, handle, True, True)   \n",
    "    \n",
    "    uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    inicio = time.time()\n",
    "    video_ids_yt = get_all_ids_playlist(youtube, uploads_playlist_id,900)\n",
    "    print(f'Time getting the video ids: {duration_string(time.time() - inicio)}')\n",
    "    channelTitle = remove_accents(channel_response['items'][0]['snippet']['title'])\n",
    "    if video_ids_yt:        \n",
    "        \n",
    "        file_path = Content_Creator_folder / f'{handle}.txt'\n",
    "        print(f'{handle} has {len(video_ids_yt)} videos')\n",
    "        new_row = handle, channelTitle, channelId, uploads_playlist_id\n",
    "        elements = video_ids_yt[:]\n",
    "        add_list_to_file(file_path, elements, sort_list = False)\n",
    "        YT_content_creators.loc[len(YT_content_creators)] = new_row\n",
    "        YT_content_creators.sort_values(by='Handle', inplace = True,  key=lambda col: col.str.lower())\n",
    "        YT_content_creators.reset_index(drop=True, inplace=True)\n",
    "        YT_content_creators.to_csv(file_path_yt_creators, index=False)\n",
    "        print(f'The duration to write the file was: {duration_string(time.time() - inicio)}')\n",
    "    else:\n",
    "        print('Handle was not added to the CSV, check the quota usage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e45b2-ecfe-46df-b0ff-4265042cba9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "uploads_playlist_id = 'UU6MfFxrAK-e4HcgJROvDJDg'\n",
    "video_ids_yt = get_all_ids_playlist(youtube, uploads_playlist_id,900)\n",
    "info_videos = []\n",
    "for video_id in video_ids_yt:\n",
    "    response = get_response_video_id(video_id)\n",
    "    snippet = response['items'][0]['snippet']\n",
    "    contentDetails = response['items'][0]['contentDetails']\n",
    "    publishedAt = snippet['publishedAt']\n",
    "    title = snippet['title']\n",
    "    channelId = snippet['channelId']\n",
    "    duration_iso = contentDetails.get('duration', 'PT0S')\n",
    "    duration = isodate.parse_duration(duration_iso).total_seconds()\n",
    "    info_videos.append((publishedAt, yt_url+video_id, title, channelId, duration))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471f817-7950-4469-86c7-90936fdcf8da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_videos = sorted(info_videos, key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for video in sorted_videos:\n",
    "    for v in video:\n",
    "        print(v)\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65fe5d4-9a62-4de5-ac62-68cd658abff3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Add a playlist into the Data Frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e2cb1-5c91-4444-8980-4c3c6ab53a1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "YT_content_creators = pd.read_csv(file_path_yt_creators)\n",
    "\n",
    "playlist_files = list(playlist_folder.glob('*.txt'))\n",
    "youtube_names = [playlist.stem.replace('_', ' ').strip() for playlist in playlist_files]\n",
    "playlist_ID = get_video_id(input(\"Playlist ID: \").strip())\n",
    "continue_addition = True\n",
    "if playlist_ID in YT_content_creators['Uploads ID'].values:\n",
    "    print(f'The Playlist: {playlist_ID} is already in Data Frame')\n",
    "\n",
    "else:\n",
    "    response = get_response_from_playlist_id(playlist_ID)\n",
    "    Channel_Name = response['items'][0]['snippet']['channelTitle']\n",
    "    Channel_ID = response['items'][0]['snippet']['channelId']\n",
    "    Handle = remove_accents(response['items'][0]['snippet']['title'].replace(' ', '_').lower())\n",
    "    other_options = ['Other Videos', 'Create a new Playlist']\n",
    "    youtube_names.extend(other_options)\n",
    "    option_choosen = choose_option(youtube_names)\n",
    "    if option_choosen == other_options[0]:\n",
    "        print('Video not added in any particular Playlist')\n",
    "    elif option_choosen == other_options[-1]:\n",
    "        new_playlist = remove_accents(input('Name of the new Playlist: ').strip())\n",
    "        file = new_playlist.replace(' ', '_') + '.txt'\n",
    "        playlist_handle_filepath = playlist_folder / file\n",
    "        add_element_to_file(playlist_handle_filepath, handle, True, True)\n",
    "\n",
    "    else:\n",
    "        file = option_choosen.replace(' ','_') + '.txt'\n",
    "        playlist_handle_filepath = playlist_folder / file\n",
    "        add_element_to_file(playlist_handle_filepath, Handle, sort_list = True, print_statement = False)   \n",
    "        \n",
    "    video_ids_yt = get_all_ids_playlist(youtube, playlist_ID,900)\n",
    "    elements = video_ids_yt[1:]\n",
    "    file_path = Content_Creator_folder / f'{Handle}.txt'\n",
    "    add_list_to_file(file_path, elements, sort_list = False)\n",
    "    new_row = Handle, Channel_Name, Channel_ID, playlist_ID\n",
    "    YT_content_creators.loc[len(YT_content_creators)] = new_row\n",
    "    YT_content_creators.sort_values(by='Handle', inplace = True,  key=lambda col: col.str.lower())\n",
    "    YT_content_creators.reset_index(drop=True, inplace=True)\n",
    "    YT_content_creators.to_csv(file_path_yt_creators, index=False)\n",
    "    print(new_row)\n",
    "    YT_content_creators = pd.read_csv(file_path_yt_creators)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(Handle)\n",
    "    print(Channel_Name)\n",
    "    YT_content_creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279270ca-4bd6-410e-8cf5-9459cb000d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4164b3ea-38a1-4969-84b3-dbad35f08b5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "read_text().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896afec-8b65-4a0c-b259-882d5f2e972f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **GET ALL THE VIDEO IDS IN FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22c765-b115-44ea-8775-85c7cea12650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in Content_Creator_folder.iterdir():\n",
    "    if file.suffix == '.txt':\n",
    "        print(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accec6ae-4740-466c-b458-63edb4ea8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = input(\"Content creator's handle: \").strip().lower()\n",
    "file = Content_Creator_folder / f'{creator}.txt'\n",
    "if file.exists():\n",
    "    video_ids = file.read_text().splitlines()\n",
    "    video_ids.reverse()\n",
    "    print(len(video_ids))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Files dosen't exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79ff4f-0251-4205-808b-de7c6173db39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "num_video_id = len(video_ids)\n",
    "digits = len(str(num_video_id))\n",
    "shorts_videos = []\n",
    "not_short = []\n",
    "start = time.time()\n",
    "for index, video_id in enumerate(video_ids, 1):\n",
    "    # print(f'{index:0{digits}d} {yt_url}{video_id}')\n",
    "    print(f'{index:0{digits}d} / {num_video_id} | {(index/num_video_id)*100:.2f}% | {duration_string(time.time() - start)} ', end='\\r')\n",
    "    if is_short(video_id):\n",
    "        shorts_videos.append(video_id)\n",
    "    else:\n",
    "        not_short.append(video_id)\n",
    "total = time.time() - start\n",
    "clear_output(wait=False)\n",
    "print(duration_string(total))\n",
    "print(f'There are {len(shorts_videos)} shorts videos')\n",
    "print(f'There are {len(not_short)} regular videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0deba5-1e66-427c-84f3-682582221362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, video_id in enumerate(video_ids, 1):\n",
    "    if video_id not in shorts_videos:\n",
    "        not_short.append(video_id)\n",
    "\n",
    "len(not_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e430ef9-289f-4533-b078-51df89fd79ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd433c29-258d-4c94-87f2-4b9c57ac3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74d3a5-6c9b-48f0-a877-60b7b3d1fcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd7427-e8ee-452d-bae6-751ec2e5af85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11542a9-c9cf-4c8e-abe5-38d67329a769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
